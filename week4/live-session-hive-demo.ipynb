{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Hive\n",
    "\n",
    "### what is Hive?\n",
    "https://hive.apache.org/\n",
    "\n",
    "According to themselves ... \n",
    "*The Apache Hive â„¢ data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage using SQL. *\n",
    "\n",
    "2 key points to remember\n",
    "* the data is stored in \"regular\" files in hdfs, not in a relational database like postgres\n",
    "* the Hive program allows you to write SQL statements to query the data as if it was in a relational database\n",
    "\n",
    "### how does it work?\n",
    "\n",
    "1. in order to tell Hive that you want to treat a \"regular\" file like a database you have to make a mapping from the data to a SQL-like table\n",
    "2. when you execute a SQL command, Hive translates that into a map-reduce job to actually return the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's try to do something in hadoop and hive\n",
    "\n",
    "1. start your EC2 instance\n",
    "1. ssh/login\n",
    "1. as root start hadoop, hive and postgres\n",
    "```\n",
    "cd /\n",
    ". start_hadoop.sh\n",
    "/data/start_postgres.sh\n",
    "```\n",
    "\n",
    "1. become the w205 user\n",
    "```\n",
    "su - w205\n",
    "```\n",
    "\n",
    "1. create/download the foo.csv text file\n",
    "\n",
    "1. put the data in hdfs and check it is there\n",
    "```\n",
    "hdfs dfs -put foo.csv\n",
    "hdfs dfs -ls\n",
    "```\n",
    "\n",
    "1. start hive and get the hive prompt `hive> `\n",
    "```\n",
    "hive\n",
    "```\n",
    "\n",
    "1. check what tables we have (don't forget the semicolon at the end of each line)\n",
    "```\n",
    "show tables;\n",
    "```\n",
    "\n",
    "1. now insert the data into the table\n",
    "```\n",
    "CREATE EXTERNAL TABLE foo (\n",
    "    name string,\n",
    "    age int\n",
    ")\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "STORED AS TEXTFILE\n",
    "location '/user/w205/foo'\n",
    "```\n",
    "\n",
    "1. check out our new table and see what the schema is\n",
    "```\n",
    "show tables;\n",
    "describe foo;\n",
    "```\n",
    "\n",
    "1. do our first query\n",
    "```\n",
    "select count(*) from foo;\n",
    "```\n",
    "\n",
    "1. some other queries\n",
    "```\n",
    "select * from foo where age > 40;\n",
    "select * from foo where age < 20;\n",
    "select avg(age) from foo;\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lets try to screw up on purpose\n",
    "\n",
    "You only specify the directory of the data, not the data file itself\n",
    "\n",
    "this should break!!!\n",
    "\n",
    "```\n",
    "CREATE EXTERNAL TABLE foo2 (\n",
    "    name string,\n",
    "    age int\n",
    ")\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "STORED AS TEXTFILE\n",
    "location '/user/w205/foo/foo.csv'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
